"""
RISK SCORING MODEL (VERSION AVEC GRIDSEARCHCV)
==============================================
Ce module :
- entraÃ®ne un modÃ¨le de scoring locataire
- utilise GridSearchCV pour optimiser les hyperparamÃ¨tres
- prÃ©dit un score de risque (0â€“100)
- sauvegarde le modÃ¨le pour l'API FastAPI
"""

import pandas as pd
import pickle
from pathlib import Path

from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, r2_score

# =========================
# PATHS
# =========================
DATA_PATH = Path("datasets/raw/tenant_risk.csv")
MODEL_PATH = Path("models/risk_scoring_model.pkl")

# =========================
# GRIDSEARCHCV CONFIGURATION
# =========================
USE_GRIDSEARCH = True  # Mettre Ã  False pour entraÃ®nement rapide

PARAM_GRID = {
    'n_estimators': [50, 100, 200],
    'max_depth': [5, 10, 15, None],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'max_features': ['sqrt', 'log2']
}

# =========================
# TRAINING FUNCTION
# =========================
def train_risk_model():
    print("=" * 60)
    print("ðŸš€ ENTRAÃŽNEMENT DU MODÃˆLE RISK SCORING")
    if USE_GRIDSEARCH:
        print("ðŸŽ¯ MODE: GridSearchCV (Hyperparameter Tuning)")
    else:
        print("âš¡ MODE: EntraÃ®nement rapide")
    print("=" * 60)

    # ===========================
    # 1ï¸âƒ£ CHARGER LES DONNÃ‰ES
    # ===========================
    if not DATA_PATH.exists():
        raise FileNotFoundError(f"âŒ Dataset introuvable: {DATA_PATH}")

    df = pd.read_csv(DATA_PATH)
    print(f"ðŸ“Š Dataset chargÃ©: {len(df)} tenants")

    # ===========================
    # 2ï¸âƒ£ FEATURES (X) et TARGET (y)
    # ===========================
    X = df[[
        "income",
        "debt_ratio",
        "total_bookings",
        "cancellations",
        "late_cancellations",
        "avg_rating"
    ]]

    y = df["risk_score"]

    print(f"\nðŸ“ˆ Statistiques du risk_score:")
    print(f"   Min:  {y.min():.0f}")
    print(f"   Max:  {y.max():.0f}")
    print(f"   Mean: {y.mean():.2f}")
    print(f"   Std:  {y.std():.2f}")

    # ===========================
    # 3ï¸âƒ£ TRAIN / TEST SPLIT
    # ===========================
    X_train, X_test, y_train, y_test = train_test_split(
        X, y,
        test_size=0.2,
        random_state=42
    )

    print(f"\nðŸ”€ Split des donnÃ©es:")
    print(f"   Train: {len(X_train)} tenants")
    print(f"   Test:  {len(X_test)} tenants")

    # ===========================
    # 4ï¸âƒ£ MODÃˆLE + GRIDSEARCHCV
    # ===========================

    if USE_GRIDSEARCH:
        print(f"\nðŸŽ¯ GRIDSEARCHCV - RECHERCHE DES MEILLEURS HYPERPARAMÃˆTRES")
        print(f"   ParamÃ¨tres Ã  tester:")
        for param, values in PARAM_GRID.items():
            print(f"      {param}: {values}")

        total_combinations = 1
        for values in PARAM_GRID.values():
            total_combinations *= len(values)
        print(f"\n   Total de combinaisons: {total_combinations}")
        print(f"   Cross-validation: 5 folds")
        print(f"   Total d'entraÃ®nements: {total_combinations * 5}")
        print(f"\n   â³ Cela peut prendre 2-5 minutes...")

        # GridSearchCV
        base_model = RandomForestRegressor(random_state=42)

        grid_search = GridSearchCV(
            estimator=base_model,
            param_grid=PARAM_GRID,
            cv=5,
            scoring='neg_mean_absolute_error',
            n_jobs=-1,
            verbose=1
        )

        grid_search.fit(X_train, y_train)

        # Meilleurs paramÃ¨tres
        print(f"\nâœ… MEILLEURS HYPERPARAMÃˆTRES TROUVÃ‰S:")
        for param, value in grid_search.best_params_.items():
            print(f"   {param}: {value}")

        print(f"\nðŸ“Š Meilleur score CV: {-grid_search.best_score_:.2f} MAE")

        model = grid_search.best_estimator_

    else:
        print(f"\nðŸ¤– EntraÃ®nement du modÃ¨le avec paramÃ¨tres par dÃ©faut...")

        model = RandomForestRegressor(
            n_estimators=100,
            random_state=42
        )

        model.fit(X_train, y_train)
        print("âœ… ModÃ¨le entraÃ®nÃ©!")

    # ===========================
    # 5ï¸âƒ£ Ã‰VALUATION
    # ===========================
    print(f"\nðŸ“Š Ã‰VALUATION DU MODÃˆLE:")

    predictions = model.predict(X_test)
    mae = mean_absolute_error(y_test, predictions)
    r2 = r2_score(y_test, predictions)

    print(f"   MAE: {mae:.2f} points")
    print(f"   RÂ² Score: {r2:.3f}")
    print(f"\n   InterprÃ©tation:")
    print(f"   - Erreur moyenne: ~{mae:.0f} points sur 100")
    print(f"   - Variance expliquÃ©e: {r2*100:.1f}%")

    # Feature importance
    feature_importance = pd.DataFrame({
        'feature': X.columns,
        'importance': model.feature_importances_
    }).sort_values('importance', ascending=False)

    print(f"\nðŸŽ¯ Importance des features:")
    for idx, row in feature_importance.iterrows():
        print(f"   {row['feature']:20s} {row['importance']*100:5.1f}%")

    # ===========================
    # 6ï¸âƒ£ SAUVEGARDE DU MODÃˆLE
    # ===========================
    MODEL_PATH.parent.mkdir(exist_ok=True)

    model_data = {
        'model': model,
        'feature_names': list(X.columns),
        'mae': mae,
        'r2': r2,
        'best_params': grid_search.best_params_ if USE_GRIDSEARCH else None
    }

    with open(MODEL_PATH, "wb") as f:
        pickle.dump(model_data, f)

    print(f"\nðŸ’¾ ModÃ¨le sauvegardÃ© dans: {MODEL_PATH}")

    # ===========================
    # 7ï¸âƒ£ TEST RAPIDE
    # ===========================
    print(f"\nðŸ§ª TEST RAPIDE:")
    test_tenant = {
        'income': 7000,
        'debt_ratio': 0.3,
        'total_bookings': 5,
        'cancellations': 1,
        'late_cancellations': 0,
        'avg_rating': 4.5
    }

    X_test_single = pd.DataFrame([test_tenant])
    predicted_risk = model.predict(X_test_single)[0]

    print(f"   Tenant test: {test_tenant}")
    print(f"   Risque prÃ©dit: {predicted_risk:.0f}/100")

    print("=" * 60)
    print("âœ… ENTRAÃŽNEMENT TERMINÃ‰ AVEC SUCCÃˆS!")
    print("=" * 60)

    return model


# =========================
# CLASSE POUR UTILISATION EN PROD
# =========================
class RiskScoringModel:
    """
    Wrapper pour charger et utiliser le modÃ¨le en production
    """

    def __init__(self):
        if not MODEL_PATH.exists():
            raise FileNotFoundError(
                f"âŒ ModÃ¨le Risk Scoring introuvable: {MODEL_PATH}\n"
                f"   Lancez: python app/services/scoring_model.py"
            )

        with open(MODEL_PATH, "rb") as f:
            model_data = pickle.load(f)

        # CompatibilitÃ© avec ancien format
        if isinstance(model_data, dict):
            self.model = model_data['model']
            self.feature_names = model_data.get('feature_names', [])
            self.mae = model_data.get('mae', None)
            self.r2 = model_data.get('r2', None)
            self.best_params = model_data.get('best_params', None)
        else:
            self.model = model_data
            self.feature_names = []
            self.mae = None
            self.r2 = None
            self.best_params = None

        print(f"âœ… ModÃ¨le Risk Scoring chargÃ© depuis {MODEL_PATH}")
        if self.best_params:
            print(f"   ðŸŽ¯ ModÃ¨le optimisÃ© avec GridSearchCV")

    def predict(self, data: dict) -> int:
        """
        PrÃ©dit le score de risque (0â€“100)
        """
        features = [[
            data["income"],
            data["debt_ratio"],
            data["total_bookings"],
            data["cancellations"],
            data["late_cancellations"],
            data["avg_rating"]
        ]]

        score = int(self.model.predict(features)[0])
        return min(max(score, 0), 100)


# =========================
# MAIN
# =========================
if __name__ == "__main__":
    train_risk_model()